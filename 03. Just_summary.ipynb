{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the de-duplicated reviews\n",
    "data = pd.read_pickle('deduped_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and utility functions\n",
    "\n",
    "def rearrange_score():\n",
    "    '''This function will make every score greater than 3 as positive\n",
    "        and something less than 3 as negative'''\n",
    "    score = data.Score.tolist()\n",
    "    for i in range(len(score)):\n",
    "        if(score[i]>3):\n",
    "            score[i]=1\n",
    "        else:\n",
    "            score[i]=0\n",
    "    data['Score'] = score\n",
    "    \n",
    "def remove_htmltags(df,cn):\n",
    "    '''This function will remove the html tags'''\n",
    "    col = df[cn].tolist()\n",
    "    from bs4 import BeautifulSoup\n",
    "    for i in range(len(col)):\n",
    "        soup = BeautifulSoup(col[i], \"lxml\")        \n",
    "        col[i] = soup.get_text()\n",
    "    df[cn] = col\n",
    "    return df\n",
    "\n",
    "def remove_punctuation(df,cn):\n",
    "    '''This function will remove almost every puntuation marks except \\' '''\n",
    "    col = df[cn].tolist()\n",
    "    import re\n",
    "    for i in range(len(col)):\n",
    "        col[i] = re.sub('[^A-Za-z0-9\\s\\']+', '', col[i])\n",
    "    df[cn] = col\n",
    "    return df\n",
    "\n",
    "def drop_cols(df,cols):\n",
    "    '''This function will drop the unnecessary columns'''\n",
    "    df = df.drop(labels=cols,axis=1)\n",
    "    return df\n",
    "\n",
    "def make_lower(df,cn):\n",
    "    col = df[cn].tolist()\n",
    "    for i in range(len(col)):\n",
    "        col[i] = col[i].lower()\n",
    "    df[cn]=col\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've noticed an anamoly in a certain summary. Let's remove it first from the dataframe\n",
    "\n",
    "summary = data['Summary'].tolist()\n",
    "index_to_remove = list()\n",
    "\n",
    "import math\n",
    "for i in range(len(summary)):\n",
    "    try:\n",
    "        if(math.isnan(summary[i])):\n",
    "            index_to_remove.append(i)\n",
    "    except:\n",
    "        _ = None\n",
    "        \n",
    "data = data.drop(data.index[index_to_remove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.Score != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366401, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the functions\n",
    "\n",
    "cols_to_drop = set(data.columns) - {'Summary','Score'}\n",
    "\n",
    "data = drop_cols(data,list(cols_to_drop))\n",
    "\n",
    "rearrange_score()\n",
    "\n",
    "data = remove_htmltags(data,'Summary')\n",
    "\n",
    "data = remove_punctuation(data,'Summary')\n",
    "\n",
    "data = make_lower(data,'Summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>good quality dog food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>not as advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>delight says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cough medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                Summary\n",
       "0      1  good quality dog food\n",
       "1      0      not as advertised\n",
       "2      1    delight says it all\n",
       "3      0         cough medicine\n",
       "4      1            great taffy"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('only_summary') # Saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('only_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the dataset\n",
    "\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanjay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Utility functions and algorithm\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def metric(observed,predicted):\n",
    "    '''Prints different metric btaking in observed and predicted value'''\n",
    "    pre_rec = precision_recall_fscore_support(observed,predicted)\n",
    "    roc_auc = roc_auc_score(observed,predicted)\n",
    "    print ('---Precision:---\\n{}\\n---Recall:---\\n{}\\n---fscore:---\\n{}\\n---AUC:---\\n{}'.format(pre_rec[0],pre_rec[1],pre_rec[2],roc_auc))\n",
    "    \n",
    "    \n",
    "def lr_classifier(X_train,X_test,y_train,param):\n",
    "    '''Logistic regression with hyperparameter tuning'''\n",
    "    lr = LogisticRegression(class_weight= 'balanced',n_jobs=-1,penalty='l1')\n",
    "    clf = GridSearchCV(lr,param)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    lr_parameters = lr.get_params()\n",
    "    lr_parameters['C'] = clf.best_params_['C']\n",
    "\n",
    "    lr.set_params(**lr_parameters)\n",
    "    print ('\\n---Parameters for LR---\\n{}'.format(lr.get_params))\n",
    "\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    return (y_pred) \n",
    "\n",
    "def nb_classifier(X_train,X_test,y_train,param):\n",
    "    '''Naive Bayes with hyper parameter tuning'''\n",
    "    nb = MultinomialNB(class_prior=[1,1])\n",
    "    clf = GridSearchCV(nb,param)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    nb_parameters = nb.get_params()\n",
    "    nb_parameters['alpha'] = clf.best_params_['alpha']\n",
    "\n",
    "    nb.set_params(**nb_parameters)\n",
    "    print ('\\n---Parameters for NB---\\n{}'.format(nb.get_params))\n",
    "\n",
    "    nb.fit(X_train,y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    \n",
    "    return (y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf on summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366401, 40152)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tfidf features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=0)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['Summary'])\n",
    "tfidf_features.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set -- 293120\n",
      "Size of test set -- 73281\n"
     ]
    }
   ],
   "source": [
    "l = int(0.8*data.shape[0])\n",
    "print ('Size of training set -- {}\\nSize of test set -- {}'.format(l,data.shape[0]-l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Parameters for NB---\n",
      "<bound method BaseEstimator.get_params of MultinomialNB(alpha=4, class_prior=[1, 1], fit_prior=True)>\n",
      "\n",
      "===METRICS===\n",
      "---Precision:---\n",
      "[ 0.60732334  0.93425911]\n",
      "---Recall:---\n",
      "[ 0.64561867  0.92345703]\n",
      "---fscore:---\n",
      "[ 0.62588577  0.92882666]\n",
      "---AUC:---\n",
      "0.7845378497734821\n"
     ]
    }
   ],
   "source": [
    "# Performing Naive Bayes on tfidf approach\n",
    "\n",
    "alpha = [0.125,0.25,0.5,1,2,4,8]\n",
    "parameter = {'alpha':alpha}\n",
    "\n",
    "y_pred = nb_classifier(tfidf_features[:l],tfidf_features[l:],data.Score[:l],parameter)\n",
    "\n",
    "print ('\\n===METRICS===')\n",
    "metric(data.Score[l:],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Parameters for LR---\n",
      "<bound method BaseEstimator.get_params of LogisticRegression(C=4, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>\n",
      "\n",
      "===METRICS===\n",
      "---Precision:---\n",
      "[ 0.62178937  0.96666437]\n",
      "---Recall:---\n",
      "[ 0.82932629  0.9075025 ]\n",
      "---fscore:---\n",
      "[ 0.71071698  0.93614966]\n",
      "---AUC:---\n",
      "0.8684143954831502\n"
     ]
    }
   ],
   "source": [
    "# Performing Logistic regression on tfidf approach\n",
    "\n",
    "parameter = {'C':[0.125,0.25,0.5,1,2,4,8]}\n",
    "\n",
    "y_pred = lr_classifier(tfidf_features[:l],tfidf_features[l:],data.Score[:l],parameter)\n",
    "\n",
    "print ('\\n===METRICS===')\n",
    "metric(data.Score[l:],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V on summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('only_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanjay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and loading google's w2v model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'has' in model.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for W2v model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def center_scale(X):\n",
    "    '''This function standardizes the features'''\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    return X\n",
    "\n",
    "def get_avg_vector(df):\n",
    "    \n",
    "    summary = df['Summary'].tolist()\n",
    "    vectorlist = list()\n",
    "    \n",
    "    for i in range(len(summary)):\n",
    "        \n",
    "        sen_vec = np.zeros(shape=(300,))\n",
    "        N = 0\n",
    "        \n",
    "        for word in summary[i].split():\n",
    "            if (word in model.vocab.keys()):\n",
    "                sen_vec = sen_vec + model[word]\n",
    "                N = N + 1\n",
    "        \n",
    "        if(N != 0):\n",
    "            vectorlist.append(sen_vec)\n",
    "        else:\n",
    "            vectorlist.append(np.zeros(shape=(300,)))\n",
    "\n",
    "    return (vectorlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(shape=(5,)) / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the 300 dim mean weighted vector\n",
    "\n",
    "avg_w2v = get_avg_vector(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan(X):\n",
    "    '''This functions checks and returns the position of NaN values if present any'''\n",
    "    import math\n",
    "    positions = list()\n",
    "    for i in range(len(X)):\n",
    "        if(math.isnan(X[i][0])):\n",
    "            positions.append(i)\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def modify_nan(X,positions):\n",
    "    for i in positions:\n",
    "        X[i] = np.zeros(shape=(300,))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = check_nan(avg_w2v)\n",
    "\n",
    "avg_w2v = modify_nan(avg_w2v,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the values\n",
    "\n",
    "avg_w2v = center_scale(avg_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Parameters for LR---\n",
      "<bound method BaseEstimator.get_params of LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>\n",
      "\n",
      "===METRICS===\n",
      "---Precision:---\n",
      "[ 0.48226881  0.96822094]\n",
      "---Recall:---\n",
      "[ 0.85424258  0.82883977]\n",
      "---fscore:---\n",
      "[ 0.61649239  0.89312511]\n",
      "---AUC:---\n",
      "0.841541176023826\n"
     ]
    }
   ],
   "source": [
    "# Performing Logistic regression on tfidf approach\n",
    "\n",
    "parameter = {'C':[0.125,0.25,0.5,1,2,4,8]}\n",
    "\n",
    "y_pred = lr_classifier(avg_w2v[:l],avg_w2v[l:],data.Score[:l],parameter)\n",
    "\n",
    "print ('\\n===METRICS===')\n",
    "metric(data.Score[l:],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
