{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obejctives:\n",
    "***\n",
    "* Baseline algorithms using BOW.\n",
    "* Feature enginnering like tfidf, mean weighted W2V, tfidf weighted W2V.\n",
    "* Introduction of class weights in the baseline algorithms.\n",
    "* Store the prediction of the validating dataset and analyse the misclassified points.\n",
    "* Try Xgboost on the features of W2V.\n",
    "* Use Glove(pre-trained model)\n",
    "\n",
    "[These are rough objectives that I had set out for doing the projects, I may or may not stick exactly to it.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript:\n",
    "***\n",
    "During cleaning and pre-processing the data, I had set the ratings lower than 3 as **negative** and higher than 3 as **positive**.<br>\n",
    "I had extracted the reviews and summary and then concatenated them, the summary after the text of the review.<br>\n",
    "Then I had removed HTML tags as upon manually seeing the data, I found out that there were HTML tags especally breaks. This is due to the fact that the Reviews are raw. For removing HTML tags, I had used regular expression.<br>\n",
    "Then I had removed punctuation marks and saved the data(un-stemmed). I also stemmed the data and saved it in another file as I wanted to see how stemming affects W2V. My hypothesis was since W2V produces vectors for words, stemmed or un-stemmed data would have very similar vectors and wouldn't affect the results much.<br>\n",
    "Train-test split was done on timestamp. First 80% was taken as train and the lastt 20% was taken as test.<br>\n",
    "I did hyperparameter tuning by simply trying out bunch of regularization weights. Didn't use GridSearchCV(sklearn) due to hardware restrictions.\n",
    "<br><br>\n",
    "Used Count Vectorizer for BOW and Tfidf transformer on the BOW to convert it into tfidf \n",
    "#### Observations:\n",
    "* BOW\n",
    "\n",
    "|Algorithm|AUC (NCW)|AUC (CW)\n",
    "|---|---|---|\n",
    "|Multinomial NB   |0.86   |0.88   |\n",
    "|Bernoulli's NB   |0.79   |0.83   |\n",
    "|Logistic Regression L1   |0.87   |0.91   |\n",
    "|Logistic Regression L2 | 0.87| 0.91|\n",
    "\n",
    "* TFIDF: \n",
    "\n",
    "|Algorithm|AUC (NCW)|AUC (CW)\n",
    "|---|---|---|\n",
    "|Multinomial NB   |0.54   |0.76   |\n",
    "|Bernoulli's NB   |0.79   |0.83   |\n",
    "|Logistic Regression L1   |0.87   |0.92   |\n",
    "|Logistic Regression L2 | 0.87| 0.92|\n",
    "\n",
    "*NCW - No class weights<br> CW - with Class weights*\n",
    "\n",
    "\n",
    "So introducing class weight definitely helped\n",
    "\n",
    "After BOW and tfidf, I tried self-trained W2V(gensim). First I tried mean weighted W2V for sentences and then tfidf weighted W2V. Vector size that I used is 500. I tried with several other vector size, I found 500 to give good enough results with the hardware that I'm using.<br>\n",
    "I also tried with stemmed and non stemmed data. I found that non-stemmed gave slightly better results than stemmed data and hence I stuck with non-stemmed data.\n",
    "\n",
    "* W2V\n",
    "\n",
    "|Algorithm|AUC (NCW)|AUC (CW)\n",
    "|---|---|---|\n",
    "|Logistic Regression L1   |0.86   |0.91   |\n",
    "|Logistic Regression L2 | 0.86| 0.91|\n",
    "\n",
    "* Tf-idf weighted W2V\n",
    "\n",
    "|Algorithm|AUC (NCW)|AUC (CW)\n",
    "|---|---|---|\n",
    "|Logistic Regression L1   |0.85   |0.90   |\n",
    "|Logistic Regression L2 | 0.85| 0.90|\n",
    "\n",
    "I performed all of these without removal of stopwords. I also tried the LR with tfidf with stopwords removed. It didn't give better results and hence I kept the stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of the above I chose Logistic Regression on Tfidf because it was giving me the best results. Now I did analysis on the misclassified points.\n",
    "\n",
    "Around 80% of the misclassified points were predicted as **Negative** and the rest 20% were predicted as **Positive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've downloaded Google's pre-trained W2V. I was getting an error while predicting over validation set [I'm using simple LR] because there were some NAN values in my validation set. I got rid of them and then calculated the AUC. It's coming out as 0.87 which is less than my previous models. \n",
    "\n",
    "This is no good. Now I'll separate the summary and text of the review and train on them, not together. Let's see if it changes anything.\n",
    "\n",
    "Using only the text from review worsens it to an AUC of 0.84"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
