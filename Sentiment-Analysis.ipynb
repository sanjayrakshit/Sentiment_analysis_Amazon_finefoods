{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analysis-Amazon-fine-foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/Reviews.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension after eliminating duplicates (396309, 10)\n"
     ]
    }
   ],
   "source": [
    "imp_cols = set(df.columns)-{'Id','ProductId'}\n",
    "df = df.drop_duplicates(subset=imp_cols)\n",
    "print ('Dimension after eliminating duplicates',df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "    1. Neglecting 3 star reviews \n",
    "    2. Sorting by time-stamp\n",
    "    3. Extracting Reviews and Summary and concatenating them\n",
    "    4. Defining <3 score as negative and >3 as positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366402, 366402)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.Score != 3]\n",
    "df = df.sort_values(by='Time')\n",
    "temp1 = df.Text.tolist(); temp2 = df.Summary.tolist()\n",
    "X = [str(temp1[i])+' '+str(temp2[i]) for i in range(len(temp1))]\n",
    "Y = []\n",
    "for i in df.Score.tolist():\n",
    "    if(i>3):\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(0)\n",
    "del df, temp1, temp2\n",
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "* Removing HTML tags\n",
    "* Make in lower case\n",
    "* Tokenizing and removing stopwords with punctuation marks\n",
    "* Also removing non alpha numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'movie', 'movie', 'collection', 'filled', 'comedy', 'action', 'whatever', 'else', 'want', 'call', 'great']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "X = [re.sub('<[^>]*>', '',i.lower()) for i in X] #Removes HTML tags\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "stop_word = stopwords.words('english')+\\\n",
    "['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']\n",
    "'''including punctuation marks and other chatecters in the stopwords'''\n",
    "for j in range(len(X)):\n",
    "    X[j] = [i for i in wordpunct_tokenize(X[j]) if (i not in stop_word) and (i.isalnum())]\n",
    "print (X[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stemming to normalize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "for j in range(len(X)):\n",
    "    X[j] = [ps.stem(i) for i in X[j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Storing the cleaned data to avoid running above operations in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('clean-data-XY.pkl','wb') as fp:\n",
    "    tupXY = (X,Y)\n",
    "    pickle.dump(tupXY,fp)\n",
    "fp.close()\n",
    "del tupXY, X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366402, 366402)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('clean-data-XY.pkl','rb') as fp:\n",
    "    X,Y = pickle.load(fp)\n",
    "fp.close()\n",
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'witti littl book make son laugh loud recit car drive along alway sing refrain learn whale india droop rose love new word book introduc silli classic book will bet son still abl recit memori colleg everi book educ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [' '.join(i) for i in X]\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models:\n",
    "* Throught the models, precision recall would be my metric\n",
    "* Feature used: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_metric = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count based Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256481, 27224), (109921, 27224))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "model = CountVectorizer(min_df=3,binary=False) #keeping min_df=3 will eliminate unnecessary strings\n",
    "l = int(0.7*len(X))\n",
    "model.fit(X[:l])\n",
    "BOW_tr = model.transform(X[:l])\n",
    "BOW_ts = model.transform(X[l:])\n",
    "BOW_tr.shape, BOW_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurence based Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256481, 27224), (109921, 27224))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CountVectorizer(min_df=3,binary=True)\n",
    "model.fit(X[:l])\n",
    "BBOW_tr = model.transform(X[:l])\n",
    "BBOW_ts = model.transform(X[l:])\n",
    "BBOW_tr.shape, BBOW_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multinomial Naive Baye's\n",
    "    Doing Grid-search on hyperparameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(MultinomialNB(),{'alpha':[0.5,0.25,0.125,1,2,3,4]})\n",
    "clf.fit(BOW_tr,Y[:l])\n",
    "hX = clf.predict(BOW_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.7340398 ,  0.94389242]),\n",
       " array([ 0.73643813,  0.94323636]),\n",
       " array([ 0.73523701,  0.94356427]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve\n",
    "m = precision_recall_fscore_support(Y[l:],hX)\n",
    "bs_metric.append(('Multinomial NB with Count-BOW',m[0],m[1]))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see high precision and recall for positive class, but low for negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bernoullis Naive Baye's\n",
    "    Doing grid search on hyperparameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = GridSearchCV(BernoulliNB(),{'alpha':[0.5,0.25,0.125,1,2,3,4]})\n",
    "clf.fit(BBOW_tr,Y[:l])\n",
    "hX = clf.predict(BBOW_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.69271864,  0.9411627 ]),\n",
       " array([ 0.72627321,  0.93146438]),\n",
       " array([ 0.70909919,  0.93628843]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = precision_recall_fscore_support(Y[l:],hX)\n",
    "bs_metric.append(('Bernoullis NB with Binary-BOW',m[0],m[1]))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics have decreased than MultinomialNB which was expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    L1 regularizer with gridsearch on hyperparameter c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = GridSearchCV(LogisticRegression(n_jobs=-1,penalty='l1'),{'C':[0.25,0.5,0.75,1,2,3,4]})\n",
    "clf.fit(BBOW_tr,Y[:l])\n",
    "hX = clf.predict(BBOW_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.85022106,  0.9438604 ]),\n",
       " array([ 0.72803651,  0.97271594]),\n",
       " array([ 0.78439918,  0.95807095]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = precision_recall_fscore_support(Y[l:],hX)\n",
    "bs_metric.append(('Logistic Regression-L1 regularizer',m[0],m[1]))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics have drastically improved from Naive Baye's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    L2 regularizer with gridsearch on hyperparameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(LogisticRegression(n_jobs=-1,penalty='l2'),{'C':[0.25,0.5,0.75,1,2,3,4]})\n",
    "clf.fit(BBOW_tr,Y[:l])\n",
    "hX = clf.predict(BBOW_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.85201603,  0.94381133]),\n",
       " array([ 0.72767348,  0.97311312]),\n",
       " array([ 0.78495105,  0.95823827]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = precision_recall_fscore_support(Y[l:],hX)\n",
    "bs_metric.append(('Logistic Regression-L2 regularizer',m[0],m[1]))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics are almost equal to LR with l1 regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model --- Precision --- Recall\n",
      "Multinomial NB with Count-BOW --- [ 0.7340398   0.94389242] --- [ 0.73643813  0.94323636]\n",
      "Bernoullis NB with Binary-BOW --- [ 0.69271864  0.9411627 ] --- [ 0.72627321  0.93146438]\n",
      "Logistic Regression-L1 regularizer --- [ 0.85022106  0.9438604 ] --- [ 0.72803651  0.97271594]\n",
      "Logistic Regression-L2 regularizer --- [ 0.85201603  0.94381133] --- [ 0.72767348  0.97311312]\n"
     ]
    }
   ],
   "source": [
    "print('Model --- Precision --- Recall')\n",
    "for i in bs_metric:\n",
    "    model, pre, rec = i\n",
    "    print('{} --- {} --- {}'.format(model,pre,rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Feature engineering\n",
    "* tf-idf\n",
    "* W2V\n",
    "* tf-idf based W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fe_metric = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256481, 27222), (109921, 27222))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model = TfidfVectorizer(min_df=3,strip_accents='unicode')\n",
    "model.fit(X[:l])\n",
    "#tmp = model.fit_transform(X)\n",
    "tfidf_tr = model.transform(X[:l])\n",
    "tfidf_ts = model.transform(X[l:])\n",
    "#tfidf_tr, tfidf_ts = tmp[:l], tmp[l:]\n",
    "tfidf_tr.shape, tfidf_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multinomial Naive Baye's\n",
    "    Doing Grid-search on hyperparameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(MultinomialNB(),{'alpha':[0.5,0.25,0.125,1,2,3,4]})\n",
    "clf.fit(tfidf_tr,Y[:l])\n",
    "hX = clf.predict(tfidf_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91731827,  0.87431927]),\n",
       " array([ 0.32854476,  0.99370028]),\n",
       " array([ 0.48380938,  0.93019509]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve\n",
    "m = precision_recall_fscore_support(Y[l:],hX)\n",
    "fe_metric.append(('MultinomialNB with tfidf',m[0],m[1]))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using tf-idf the precision for negative class has increased and the positive class has decreased. The recall for negative class has drastically decreased but for positive class has increased very much.\n",
    "        \n",
    "    Checking for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.92301067,  0.89851194]),\n",
       " array([ 0.36251269,  0.994671  ]),\n",
       " array([ 0.52057098,  0.9441494 ]),\n",
       " array([ 38429, 218052]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hX = clf.predict(tfidf_tr)\n",
    "m = precision_recall_fscore_support(Y[:l],hX)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bernoullis Naive Baye's\n",
    "    Doing grid search on hyperparameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = GridSearchCV(BernoulliNB(),{'alpha':[0.5,0.25,0.125,1,2,3,4]})\n",
    "clf.fit(tfidf_tr,Y[:l])\n",
    "hX = clf.predict(tfidf_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.69263106,  0.94117122]),\n",
       " array([ 0.72632507,  0.93143128]),\n",
       " array([ 0.70907802,  0.93627592]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = precision_recall_fscore_support(Y[l:],hX)\n",
    "fe_metric.append(('BernoullisNB with tfidf',m[0],m[1]))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    L1 regularizer with gridsearch on hyperparameter c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = GridSearchCV(LogisticRegression(n_jobs=-1,penalty='l1'),{'C':[0.25,0.5,0.75,1,2,3,4]})\n",
    "clf.fit(tfidf_tr,Y[:l])\n",
    "hX = clf.predict(tfidf_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.85755952,  0.94764876]),\n",
       " array([ 0.74717353,  0.97359856]),\n",
       " array([ 0.79856992,  0.96044841]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = precision_recall_fscore_support(Y[l:],hX)\n",
    "fe_metric.append(('LR(L1) with tfidf',m[0],m[1]))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    L2 regularizer with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = GridSearchCV(LogisticRegression(n_jobs=-1,penalty='l2'),{'C':[0.25,0.5,0.75,1,2,3,4]})\n",
    "clf.fit(tfidf_tr,Y[:l])\n",
    "hX = clf.predict(tfidf_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.86021505,  0.9468019 ]),\n",
       " array([ 0.74266155,  0.97432672]),\n",
       " array([ 0.79712767,  0.96036713]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = precision_recall_fscore_support(Y[l:],hX)\n",
    "fe_metric.append(('LR(L2) with tfidf',m[0],m[1]))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model --- Precision --- Recall\n",
      "MultinomialNB with tfidf --- [ 0.91731827  0.87431927] --- [ 0.32854476  0.99370028]\n",
      "BernoullisNB with tfidf --- [ 0.69263106  0.94117122] --- [ 0.72632507  0.93143128]\n",
      "LR(L1) with tfidf --- [ 0.85755952  0.94764876] --- [ 0.74717353  0.97359856]\n",
      "LR(L2) with tfidf --- [ 0.86021505  0.9468019 ] --- [ 0.74266155  0.97432672]\n"
     ]
    }
   ],
   "source": [
    "print('Model --- Precision --- Recall')\n",
    "for i in fe_metric:\n",
    "    model, pre, rec = i\n",
    "    print('{} --- {} --- {}'.format(model,pre,rec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
