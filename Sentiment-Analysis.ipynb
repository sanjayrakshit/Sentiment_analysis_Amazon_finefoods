{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analysis-Amazon-fine-foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/Reviews.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension after eliminating duplicates (396309, 10)\n"
     ]
    }
   ],
   "source": [
    "imp_cols = set(df.columns)-{'Id','ProductId'}\n",
    "df = df.drop_duplicates(subset=imp_cols)\n",
    "print ('Dimension after eliminating duplicates',df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "    1. Neglecting 3 star reviews \n",
    "    2. Sorting by time-stamp\n",
    "    3. Extracting Reviews and Summary and concatenating them\n",
    "    4. Defining <3 score as negative and >3 as positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366402, 366402)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.Score != 3]\n",
    "df = df.sort_values(by='Time')\n",
    "temp1 = df.Text.tolist(); temp2 = df.Summary.tolist()\n",
    "X = [str(temp1[i])+' '+str(temp2[i]) for i in range(len(temp1))]\n",
    "Y = []\n",
    "for i in df.Score.tolist():\n",
    "    if(i>3):\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(0)\n",
    "del df, temp1, temp2\n",
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "* Removing HTML tags\n",
    "* Make in lower case\n",
    "* Tokenizing and removing stopwords with punctuation marks\n",
    "* Also removing non alpha numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'movie', 'movie', 'collection', 'filled', 'comedy', 'action', 'whatever', 'else', 'want', 'call', 'great']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "X = [re.sub('<[^>]*>', '',i.lower()) for i in X] #Removes HTML tags\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "stop_word = stopwords.words('english')+\\\n",
    "['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']\n",
    "'''including punctuation marks and other chatecters in the stopwords'''\n",
    "for j in range(len(X)):\n",
    "    X[j] = [i for i in wordpunct_tokenize(X[j]) if (i not in stop_word) and (i.isalnum())]\n",
    "print (X[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stemming to normalize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "for j in range(len(X)):\n",
    "    X[j] = [ps.stem(i) for i in X[j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Storing the cleaned data to avoid running above operations in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('clean-data-XY.pkl','wb') as fp:\n",
    "    tupXY = (X,Y)\n",
    "    pickle.dump(tupXY,fp)\n",
    "fp.close()\n",
    "del tupXY, X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366402, 366402)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('clean-data-XY.pkl','rb') as fp:\n",
    "    X,Y = pickle.load(fp)\n",
    "fp.close()\n",
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'witti littl book make son laugh loud recit car drive along alway sing refrain learn whale india droop rose love new word book introduc silli classic book will bet son still abl recit memori colleg everi book educ'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [' '.join(i) for i in X]\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models:\n",
    "* Throught the models, precision recall would be my metric\n",
    "* Feature used: Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count based Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256481, 27224), (109921, 27224))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "model = CountVectorizer(min_df=3,binary=False) #keeping min_df=3 will eliminate unnecessary strings\n",
    "l = int(0.7*len(X))\n",
    "model.fit(X[:l])\n",
    "BOW_tr = model.transform(X[:l])\n",
    "BOW_ts = model.transform(X[l:])\n",
    "BOW_tr.shape, BOW_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurence based Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256481, 27224), (109921, 27224))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CountVectorizer(min_df=3,binary=True)\n",
    "model.fit(X[:l])\n",
    "BBOW_tr = model.transform(X[:l])\n",
    "BBOW_ts = model.transform(X[l:])\n",
    "BBOW_tr.shape, BBOW_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multinomial Naive Baye's\n",
    "    Doing Grid-search on hyperparameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(MultinomialNB(),{'alpha':[0.5,0.25,0.125,1,2,3,4]})\n",
    "clf.fit(BOW_tr,Y[:l])\n",
    "hX = clf.predict(BOW_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.7340398 ,  0.94389242]),\n",
       " array([ 0.73643813,  0.94323636]),\n",
       " array([ 0.73523701,  0.94356427]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve\n",
    "precision_recall_fscore_support(Y[l:],hX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see high precision and recall for positive class, but low for negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bernoullis Naive Baye's\n",
    "    Doing grid search on hyperparameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = GridSearchCV(BernoulliNB(),{'alpha':[0.5,0.25,0.125,1,2,3,4]})\n",
    "clf.fit(BBOW_tr,Y[:l])\n",
    "hX = clf.predict(BBOW_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.69271864,  0.9411627 ]),\n",
       " array([ 0.72627321,  0.93146438]),\n",
       " array([ 0.70909919,  0.93628843]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y[l:],hX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics have decreased than MultinomialNB which was expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    L1 regularizer with gridsearch on hyperparameter c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = GridSearchCV(LogisticRegression(n_jobs=-1,penalty='l1'),{'C':[0.25,0.5,0.75,1,2,3,4]})\n",
    "clf.fit(BBOW_tr,Y[:l])\n",
    "hX = clf.predict(BBOW_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.85021199,  0.9438503 ]),\n",
       " array([ 0.72798465,  0.97271594]),\n",
       " array([ 0.78436522,  0.95806574]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y[l:],hX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics have drastically improved from Naive Baye's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    L2 regularizer with gridsearch on hyperparameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(LogisticRegression(n_jobs=-1,penalty='l2'),{'C':[0.25,0.5,0.75,1,2,3,4]})\n",
    "clf.fit(BBOW_tr,Y[:l])\n",
    "hX = clf.predict(BBOW_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.85201603,  0.94381133]),\n",
       " array([ 0.72767348,  0.97311312]),\n",
       " array([ 0.78495105,  0.95823827]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y[l:],hX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics are almost equal to LR with l1 regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "* tf-idf\n",
    "* W2V\n",
    "* tf-idf based W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256481, 27224), (109921, 27224))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model = TfidfVectorizer(min_df=3,strip_accents='unicode')\n",
    "model.fit(X[:l])\n",
    "tfidf_tr = model.transform(X[:l])\n",
    "tfidf_ts = model.transform(X[l:])\n",
    "tfidf_tr.shape, tfidf_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multinomial Naive Baye's\n",
    "    Doing Grid-search on hyperparameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(MultinomialNB(),{'alpha':[0.5,0.25,0.125,1,2,3,4]})\n",
    "clf.fit(tfidf_tr,Y[:l])\n",
    "hX = clf.predict(tfidf_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91717347,  0.87430957]),\n",
       " array([ 0.32849289,  0.99368925]),\n",
       " array([ 0.48373301,  0.93018476]),\n",
       " array([19282, 90639]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve\n",
    "precision_recall_fscore_support(Y[l:],hX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using tf-idf the precision for negative class has increased and the positive class has decreased. The recall for negative class has drastically decreased but for positive class has increased very much.\n",
    "        \n",
    "    Checking for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.92300557,  0.89850822]),\n",
       " array([ 0.36248666,  0.994671  ]),\n",
       " array([ 0.52054334,  0.94414734]),\n",
       " array([ 38429, 218052]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hX = clf.predict(tfidf_tr)\n",
    "precision_recall_fscore_support(Y[:l],hX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
