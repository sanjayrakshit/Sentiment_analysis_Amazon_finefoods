{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on the summary \n",
    "\n",
    "Here in this notebook I will try to perform sentiment analysis by only using the summary part of the review from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the de-duplicated reviews\n",
    "\n",
    "data = pd.read_pickle('deduped_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the original dataframe looks\n",
    "<br><br>\n",
    "In the cell below there are some utility functions that'll help me throughout. Please go through their function documentation to know more about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and utility functions\n",
    "\n",
    "def rearrange_score():\n",
    "    '''This function will make every score greater than 3 as positive\n",
    "        and something less than 3 as negative'''\n",
    "    score = data.Score.tolist()\n",
    "    for i in range(len(score)):\n",
    "        if(score[i]>3):\n",
    "            score[i]=1\n",
    "        else:\n",
    "            score[i]=0\n",
    "    data['Score'] = score\n",
    "    \n",
    "def remove_htmltags(df,cn):\n",
    "    '''This function will remove the html tags'''\n",
    "    col = df[cn].tolist()\n",
    "    from bs4 import BeautifulSoup\n",
    "    for i in range(len(col)):\n",
    "        soup = BeautifulSoup(col[i], \"lxml\")        \n",
    "        col[i] = soup.get_text()\n",
    "    df[cn] = col\n",
    "    return df\n",
    "\n",
    "def remove_punctuation(df,cn):\n",
    "    '''This function will remove almost every puntuation marks except \\' '''\n",
    "    col = df[cn].tolist()\n",
    "    import re\n",
    "    for i in range(len(col)):\n",
    "        col[i] = re.sub('[^A-Za-z0-9\\s\\']+', '', col[i])\n",
    "    df[cn] = col\n",
    "    return df\n",
    "\n",
    "def drop_cols(df,cols):\n",
    "    '''This function will drop the unnecessary columns'''\n",
    "    df = df.drop(labels=cols,axis=1)\n",
    "    return df\n",
    "\n",
    "def make_lower(df,cn):\n",
    "    '''This function makes the contents of the column(cn) of dataframe(df) into lowercase'''\n",
    "    col = df[cn].tolist()\n",
    "    for i in range(len(col)):\n",
    "        col[i] = col[i].lower()\n",
    "    df[cn]=col\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've noticed an anamoly in a certain summary. Let's remove it first from the dataframe\n",
    "\n",
    "summary = data['Summary'].tolist()\n",
    "index_to_remove = list()\n",
    "\n",
    "import math\n",
    "for i in range(len(summary)):\n",
    "    try:\n",
    "        if(math.isnan(summary[i])):\n",
    "            index_to_remove.append(i)\n",
    "    except:\n",
    "        _ = None\n",
    "        \n",
    "data = data.drop(data.index[index_to_remove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the rows that have rating as 3 star since I've already decided anything >3 is positive and anything <3 as negative\n",
    "\n",
    "data = data[data.Score != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366401, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the functions\n",
    "\n",
    "# deciding which columns are unnecessary\n",
    "cols_to_drop = set(data.columns) - {'Summary','Score'}\n",
    "\n",
    "# Removing unnecessary columns\n",
    "data = drop_cols(data,list(cols_to_drop))\n",
    "\n",
    "# Rearraging score\n",
    "# less than 3: Class 0\n",
    "# greater than 3: Class 1\n",
    "rearrange_score()\n",
    "\n",
    "# Removing html tags from the summary  column of the dataframe\n",
    "data = remove_htmltags(data,'Summary')\n",
    "\n",
    "# Removing selective punctuation marks from the summary column of the dataframe\n",
    "data = remove_punctuation(data,'Summary')\n",
    "\n",
    "# turning the uppercase portions of the summary into lowercase\n",
    "data = make_lower(data,'Summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>good quality dog food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>not as advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>delight says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cough medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                Summary\n",
       "0      1  good quality dog food\n",
       "1      0      not as advertised\n",
       "2      1    delight says it all\n",
       "3      0         cough medicine\n",
       "4      1            great taffy"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how my data looks after doing all the actions in the above cells\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframe\n",
    "\n",
    "data.to_pickle('only_summary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloading the saved dataframe\n",
    "\n",
    "data = pd.read_pickle('only_summary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the dataset\n",
    "\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below I have written some utility functions and algorithms that will help me build and evaluate models in the later part of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjay/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Utility functions and algorithm\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def metric(observed,predicted):\n",
    "    '''Prints different metric btaking in observed and predicted value'''\n",
    "    pre_rec = precision_recall_fscore_support(observed,predicted)\n",
    "    roc_auc = roc_auc_score(observed,predicted)\n",
    "    print ('---Precision:---\\n{}\\n---Recall:---\\n{}\\n---fscore:---\\n{}\\n---AUC:---\\n{}'.format(pre_rec[0],pre_rec[1],pre_rec[2],roc_auc))\n",
    "    \n",
    "    \n",
    "def lr_classifier(X_train,X_test,y_train,param):\n",
    "    '''Logistic regression with hyperparameter tuning'''\n",
    "    lr = LogisticRegression(class_weight= 'balanced',n_jobs=-1,penalty='l1')\n",
    "    clf = GridSearchCV(lr,param)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    lr_parameters = lr.get_params()\n",
    "    lr_parameters['C'] = clf.best_params_['C']\n",
    "\n",
    "    lr.set_params(**lr_parameters)\n",
    "    print ('\\n---Parameters for LR---\\n{}'.format(lr.get_params))\n",
    "\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    return (y_pred) \n",
    "\n",
    "def nb_classifier(X_train,X_test,y_train,param):\n",
    "    '''Naive Bayes with hyper parameter tuning'''\n",
    "    nb = MultinomialNB(class_prior=[1,1])\n",
    "    clf = GridSearchCV(nb,param)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    nb_parameters = nb.get_params()\n",
    "    nb_parameters['alpha'] = clf.best_params_['alpha']\n",
    "\n",
    "    nb.set_params(**nb_parameters)\n",
    "    print ('\\n---Parameters for NB---\\n{}'.format(nb.get_params))\n",
    "\n",
    "    nb.fit(X_train,y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    \n",
    "    return (y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf on summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366401, 40152)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tfidf features using tfidf-vectorizer of scikit-learn \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=0)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['Summary'])\n",
    "tfidf_features.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set -- 293120\n",
      "Size of test set -- 73281\n"
     ]
    }
   ],
   "source": [
    "l = int(0.8*data.shape[0])\n",
    "print ('Size of training set -- {}\\nSize of test set -- {}'.format(l,data.shape[0]-l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Parameters for NB---\n",
      "<bound method BaseEstimator.get_params of MultinomialNB(alpha=4, class_prior=[1, 1], fit_prior=True)>\n",
      "\n",
      "===METRICS===\n",
      "---Precision:---\n",
      "[ 0.60781893  0.93332352]\n",
      "---Recall:---\n",
      "[ 0.64435913  0.92292138]\n",
      "---fscore:---\n",
      "[ 0.62555588  0.92809331]\n",
      "---AUC:---\n",
      "0.7836402578155206\n"
     ]
    }
   ],
   "source": [
    "# Performing Naive Bayes on tfidf approach\n",
    "\n",
    "alpha = [0.125,0.25,0.5,1,2,4,8]\n",
    "parameter = {'alpha':alpha}\n",
    "\n",
    "y_pred = nb_classifier(tfidf_features[:l],tfidf_features[l:],data.Score[:l],parameter)\n",
    "\n",
    "print ('\\n===METRICS===')\n",
    "metric(data.Score[l:],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Parameters for LR---\n",
      "<bound method BaseEstimator.get_params of LogisticRegression(C=4, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>\n",
      "\n",
      "===METRICS===\n",
      "---Precision:---\n",
      "[ 0.62445528  0.96787898]\n",
      "---Recall:---\n",
      "[ 0.8377105   0.90659981]\n",
      "---fscore:---\n",
      "[ 0.71553138  0.93623774]\n",
      "---AUC:---\n",
      "0.8721551511771695\n"
     ]
    }
   ],
   "source": [
    "# Performing Logistic regression on tfidf approach\n",
    "\n",
    "parameter = {'C':[0.125,0.25,0.5,1,2,4,8]}\n",
    "\n",
    "y_pred = lr_classifier(tfidf_features[:l],tfidf_features[l:],data.Score[:l],parameter)\n",
    "\n",
    "print ('\\n===METRICS===')\n",
    "metric(data.Score[l:],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V on summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the data before creating the w2v features \n",
    "\n",
    "data = pd.read_pickle('only_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the dataframe \n",
    "\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and loading google's w2v model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'has' in model.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we have 2 utility funtions. 1st one is used for standardizing the data and the 2nd one is to get the mean weighted 300 dim vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for W2v model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def center_scale(X):\n",
    "    '''This function standardizes the features'''\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    return X\n",
    "\n",
    "def get_avg_vector(df):\n",
    "    '''This fucntion created mean weighted w2v vectors on the summary part of the dataframe'''\n",
    "    summary = df['Summary'].tolist()\n",
    "    vectorlist = list()\n",
    "    \n",
    "    for i in range(len(summary)):\n",
    "        \n",
    "        sen_vec = np.zeros(shape=(300,))\n",
    "        N = 0\n",
    "        \n",
    "        for word in summary[i].split():\n",
    "            if (word in model.vocab.keys()):\n",
    "                sen_vec = sen_vec + model[word]\n",
    "                N = N + 1\n",
    "        \n",
    "        if(N != 0):\n",
    "            vectorlist.append(sen_vec)\n",
    "        else:\n",
    "            vectorlist.append(np.zeros(shape=(300,)))\n",
    "\n",
    "    return (vectorlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the 300 dim mean weighted vector\n",
    "\n",
    "avg_w2v = get_avg_vector(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we have 2 utility functions specifically for w2v models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan(X):\n",
    "    '''This functions checks and returns the position of NaN values if present any'''\n",
    "    import math\n",
    "    positions = list()\n",
    "    for i in range(len(X)):\n",
    "        if(math.isnan(X[i][0])):\n",
    "            positions.append(i)\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def modify_nan(X,positions):\n",
    "    '''this function modifies those nan values'''\n",
    "    for i in positions:\n",
    "        X[i] = np.zeros(shape=(300,))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had found out that there are some nan values that are being generated while getting the 300 dim vectors\n",
    "\n",
    "# this gets the location of the nan\n",
    "pos = check_nan(avg_w2v)\n",
    "\n",
    "# this modifies those nan in those locations\n",
    "avg_w2v = modify_nan(avg_w2v,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the values\n",
    "\n",
    "avg_w2v = center_scale(avg_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Parameters for LR---\n",
      "<bound method BaseEstimator.get_params of LogisticRegression(C=2, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)>\n",
      "\n",
      "===METRICS===\n",
      "---Precision:---\n",
      "[ 0.48675546  0.96648708]\n",
      "---Recall:---\n",
      "[ 0.84677003  0.83191451]\n",
      "---fscore:---\n",
      "[ 0.61816581  0.89416583]\n",
      "---AUC:---\n",
      "0.8393422699775088\n"
     ]
    }
   ],
   "source": [
    "# Performing Logistic regression on tfidf approach\n",
    "\n",
    "parameter = {'C':[0.125,0.25,0.5,1,2,4,8]}\n",
    "\n",
    "y_pred = lr_classifier(avg_w2v[:l],avg_w2v[l:],data.Score[:l],parameter)\n",
    "\n",
    "print ('\\n===METRICS===')\n",
    "metric(data.Score[l:],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
